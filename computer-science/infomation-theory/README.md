# 情報理論 (information theory)

## 符号理論 (coding theory)

### 通信路

<!-- TODO: 伝送率 -->

### 距離

文字数が同じ2つの単語、例えばcatとcarで、異なる文字数の数（この場合は1）をハミング距離という。単語と書いたが、もちろん文字列に拡張して考えてよい（意味のない文字列でも良いってこと）

ネットワーク上で0と1からなる情報を通信した際、ノイズによっていくつの0と1が誤ってしまったかを数えるために用いられた。

これを文字数が異なる文字列に拡張したのがレーベンシュタイン距離である。例えば、loveとmoneyのレーベンシュタイン距離は3である。

### 誤り訂正

情報を送る際、ビットの和が奇数か偶数かを予め相手に伝えておく。さらに情報の末尾に、ビットの和が奇数か偶数になるように1ビットを付与する。これを奇数/偶数パリティと呼ぶ。

パリティは情報の誤りを検知することができるが、訂正まではできないため、誤っていたら再送信するしかない。そこで訂正のために、パリティを賢く増やすことを考える。

パリティを賢く増やすとはどういうことかというと、情報の中に同じパリティの組合せに所属するビットが1つもないようにすることである。図で考えやすくするために、8ビットの情報を送ることを考える。8ビットの情報は、2マス×2マス×2マスのキューブとして捉えられる。この時、縦・横・高さの3軸でそれぞれパリティチェックを行う側・行わない側を設けると、全てのビットでパリティチェックの組合せが一意になる。ここで、全てのパリティチェックを避けた1ビットを除いた7ビットが、受信側で誤り訂正が可能な符号といえる。なお、余った1ビットは全体のパリティチェックに用いる。これをハミング符号化と呼ぶ。資料も参照。[^arai_2023]

[^arai_2023]: [符号化と通信の理論](https://www2.math.kyushu-u.ac.jp/~snii/information.pdf)

余談だけど、周期の異なるパリティを複数重ねることで誤り訂正に強くなる、って考え方は、独立な多数の因子の和として表される確率変数が正規分布に従う中心極限定理に似てるなと思った。

### 通信路の容量, シャノンの定理

<!-- エントロピー -->

<!-- TODO: 容量 -->

<!-- TODO: シャノンの定理 -->
