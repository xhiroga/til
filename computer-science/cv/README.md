# CV (Computer Vision)

## 基礎知識

### デジタル画像の撮影

歪曲収差 (distortion) とは、撮影した画像が樽型または糸巻き型に歪むこと。被写体から出た光がレンズの主点を通るとき、出射角と入射角が等しくならないことから生じる。

広角レンズでは、景色の端側の光ほど出射角の狭まり方が大きいために、端が圧縮されたようになる。これを補正せず効果として用いているのが魚眼レンズである。

画角とは、被写体のアングルのこと**ではない**。デジタルカメラはレンズを通った光を素子で捉えるが、素子が大きいほど広い範囲を写真に収められる。これはプロジェクターとスクリーンを思い浮かべると分かりやすい。素子の広さを、焦点から素子の端までの角度を用いて表し、これを画角と呼ぶ。

## 画像処理

### トーンカーブ

画素の濃淡を関数で変換することで、画像の色合いを調整できる。関数を階調変換関数といい、グラフで表したものをトーンカーブと呼ぶ。トーンカーブの形状による特徴は次の通り。

- シグモイド曲線: コントラストを上げる
- 傾きが1より大きい直線: グラフの平坦な部分の画素は真っ暗か真っ白になるが、残る箇所は濃淡の違いがはっきりする
- 傾きが1より小さい直線: 利用できる濃淡の範囲が狭まり、コントラストが下がる
- 累乗による曲線: 濃淡を$x$としたとき、$255(\frac{x}{255})^{\frac{1}{\gamma}}$として累乗で変換する。ガンマ変換またはガンマ補正と呼ぶ

### 平滑化

ぼけた写真のように画像を滑らかにすること。画素に対して、周辺の画素との濃淡の平均を取って更新する。重み付き平均を用いたり、さらに重みに正規分布（ガウス分布）を用いることもある。後者をガウシアンフィルタと呼ぶ。

### エッジ検出

### 周波数領域におけるフィルタリング

画像の描き込み度合いを定量的に測ることができれば、平滑化とエッジ鮮鋭化をパラメータの違いとして表現できる。そこで、画像を縞模様の組み合わせとして表現することで、ノイズや描き込みが多い箇所が波の密集した箇所として表現されるはずである。その考えに基づいて画像をフーリエ変換することを、空間領域の画像を周波数領域で表現し直すという。

フーリエ変換した画像には実数部と虚数部があるため、絶対値を取ることで可視化がしやすくなり、これを振幅スペクトル (amplitude spectrum)と呼ぶ。

画像をフーリエ変換することで、例えば模様の特徴を数字で語ることができ、空間周波数解析と呼ばれる。[^yama_2017]
[^yama_2017]: [画像処理工学](http://imgprolab.sys.fit.ac.jp/~yama/imgproc/lec/imgproc_imgfreq_2017.pdf)

また、低周波数成分を残して高周波数成分を除去することをローパスフィルタと呼び、画像が滑らかになる。逆に高周波数成分を残すフィルタリングをハイパスフィルタと呼び、画像のエッジを検出できる。高周波数成分を増幅させるフィルタを高域強調フィルタと呼び、エッジを強調することができる。

### 画像の復元と生成

### 幾何学的変換

画像の座標$x,y$を列ベクトルと見なしたとき、2x2の行列と列ベクトルとの内積によって表される変換を線形変換という。拡大・縮小・回転・鏡映・せん断が含まれる。Desmosによって例示した。[^desmos_linear]
[^desmos_linear]: [線形変換（拡大・縮小・鏡映・スキュー）](https://www.desmos.com/calculator/tvecrez3xu)[🔐](https://www.desmos.com/calculator/yupcktxb59)

2x2の行列と$x,y$の列ベクトルの積では、垂直・水平移動を表現できない。これは定数項が無いためである。そこで$x,y$に定数項$w$を加えるとともに、行列を3x3に拡張する。このような座標を同次座標 (homogeneous coordinates)といい、変換を射影変換と呼ぶ。特に向き合う辺の並行性が保たれるものをアフィン変換と呼ぶ。Desmosによって例示した。[^desmos_affine]
[^desmos_affine]: [アフィン変換](https://www.desmos.com/calculator/zikfcsr1bf)[🔐](https://www.desmos.com/calculator/ewqiowzhne)

## 画像解析

### 2値画像処理

ペイントソフトによるバケツ塗りを考える。連続する同じ色の領域がバケツ塗りの対象となる。連結について、上下左右を判定対象とするものを4連結といい、斜めを加えたものを8連結と呼ぶ。連結成分を洗い出すことを輪郭追跡と呼ぶ。ラスタスキャンで色の境目を見つけてから、迷路の左手法のイメージで輪郭を辿る手法が知られており、結果は輪郭の始点と軌跡の組み合わせになる。

輪郭追跡により2値画像の背景と穴が分かると、ノイズ除去に活かせる。輪郭を一回り小さくすることを収縮、大きくすることを膨張と呼ぶとき、収縮→膨張、膨張→収縮のいずれも、小さな領域や穴を不可逆に消す。これをクロージング/オープニングと呼ぶ。

### 領域処理

### パターン検出

### パターン認識

画像処理におけるパターン認識とは、分類タスクを指す。距離計算を用いるアプローチと機械学習によるアプローチがある。

画像処理では、色や形など様々な特徴を扱う。よって単位が統一されておらず、単にユークリッド距離を用いるのは不適切である。そこで、偏差ではなくZスコアを用いたものを標準化ユークリッド距離と呼ぶ。しかし、例えばRGB値とエッジをまとめて扱う場合、画像が明るいなどでRGB値に相関があれば、色の情報を必要以上に反映する恐れがある。そこで共分散を組み込んだものがマハラノビス距離である。

k平均法はクラスタリングの手法である。クラスターの中心をセントロイド (centroid)といい、セントロイドの初期値を種子点ということがある。実践的には、多めの種子点を選んで分類し、後処理として近いクラスを併合する。

主成分分析は次元削減の手法である。多次元のベクトルに行列を掛けて次元を削減する。掛ける行列を主成分ベクトル行列、得たベクトルを主成分得点と呼ぶ。

## 3次元空間とシーン

### 移動体検出

例えば防犯カメラで動きのあった瞬間だけ映像を残すなど、動画中の移動体を検出したい場合がある。予め基となる状態が分かっている場合は、それを背景として画像の差分を取ることで検出できる。これを背景差分法と呼ぶ。何が背景か分かっていない場合でも、目的のフレームとそれぞれ複数のフレームとの差分を取得し、それらの差分の共通領域を取り出すことで移動体を検出できる。これをフレーム間差分法と呼ぶ。最後に、映像を通して写っている割合が大きいものを背景、そうでないものを移動体に分類する方法を統計的背景差分法と呼ぶ。

### オプティカルフロー

フレーム間の差分の有無だけでなく、移動の方向をベクトルで示すことをオプティカルフローと呼ぶ。連続する複数のフレームで移動体を検出するのが前提となる。フレーム間で対応し合う移動体の適切な箇所を検出し、その移動のベクトルを用いる方法をブロックマッチング法と呼ぶ。

## 画像の圧縮

## References

[ディジタル画像処理](https://amzn.to/4bfCzu7)
