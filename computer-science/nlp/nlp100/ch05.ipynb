{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hiroga/.ghq/github.com/xhiroga/til/computer-science/nlp/nlp100/.venv/lib/python3.9/site-packages/pandas/util/_decorators.py:311: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
      "  return func(*args, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>surface</th>\n",
       "      <th>pos</th>\n",
       "      <th>pos1</th>\n",
       "      <th>base</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>* 0 17D 1/1 0.388993</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>人工</td>\n",
       "      <td>名詞</td>\n",
       "      <td>一般</td>\n",
       "      <td>人工</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>知能</td>\n",
       "      <td>名詞</td>\n",
       "      <td>一般</td>\n",
       "      <td>知能</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>* 1 17D 2/3 0.613549</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>（</td>\n",
       "      <td>記号</td>\n",
       "      <td>括弧開</td>\n",
       "      <td>（</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>じん</td>\n",
       "      <td>名詞</td>\n",
       "      <td>一般</td>\n",
       "      <td>じん</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>こうち</td>\n",
       "      <td>名詞</td>\n",
       "      <td>一般</td>\n",
       "      <td>こうち</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>のう</td>\n",
       "      <td>助詞</td>\n",
       "      <td>終助詞</td>\n",
       "      <td>のう</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>、</td>\n",
       "      <td>記号</td>\n",
       "      <td>読点</td>\n",
       "      <td>、</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>、</td>\n",
       "      <td>記号</td>\n",
       "      <td>読点</td>\n",
       "      <td>、</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>* 2 3D 0/0 0.758984</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>AI</td>\n",
       "      <td>名詞</td>\n",
       "      <td>一般</td>\n",
       "      <td>*</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>* 3 17D 1/5 0.517898</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>〈</td>\n",
       "      <td>記号</td>\n",
       "      <td>括弧開</td>\n",
       "      <td>〈</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>エーアイ</td>\n",
       "      <td>名詞</td>\n",
       "      <td>固有名詞</td>\n",
       "      <td>*</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>〉</td>\n",
       "      <td>記号</td>\n",
       "      <td>括弧閉</td>\n",
       "      <td>〉</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>）</td>\n",
       "      <td>記号</td>\n",
       "      <td>括弧閉</td>\n",
       "      <td>）</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>と</td>\n",
       "      <td>助詞</td>\n",
       "      <td>格助詞</td>\n",
       "      <td>と</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>は</td>\n",
       "      <td>助詞</td>\n",
       "      <td>係助詞</td>\n",
       "      <td>は</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>、</td>\n",
       "      <td>記号</td>\n",
       "      <td>読点</td>\n",
       "      <td>、</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 surface   pos  pos1  base\n",
       "4   * 0 17D 1/1 0.388993  None  None  None\n",
       "5                     人工    名詞    一般    人工\n",
       "6                     知能    名詞    一般    知能\n",
       "7   * 1 17D 2/3 0.613549  None  None  None\n",
       "8                      （    記号   括弧開     （\n",
       "9                     じん    名詞    一般    じん\n",
       "10                   こうち    名詞    一般   こうち\n",
       "11                    のう    助詞   終助詞    のう\n",
       "12                     、    記号    読点     、\n",
       "13                     、    記号    読点     、\n",
       "14   * 2 3D 0/0 0.758984  None  None  None\n",
       "15                    AI    名詞    一般     *\n",
       "16  * 3 17D 1/5 0.517898  None  None  None\n",
       "17                     〈    記号   括弧開     〈\n",
       "18                  エーアイ    名詞  固有名詞     *\n",
       "19                     〉    記号   括弧閉     〉\n",
       "20                     ）    記号   括弧閉     ）\n",
       "21                     と    助詞   格助詞     と\n",
       "22                     は    助詞   係助詞     は\n",
       "23                     、    記号    読点     、"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pandas import DataFrame\n",
    "df: DataFrame = pd.read_table('./data/ai.ja.txt.parsed', sep='\\t|,', header=None, usecols=[0, 1, 2, 7], names=['surface', 'pos', 'pos1', 'base'], skiprows=1)\n",
    "df = df[4:-1]\n",
    "df.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 40. 係り受け解析結果の読み込み（形態素）\n",
    "# 41. 係り受け解析結果の読み込み（文節・係り受け）\n",
    "\n",
    "from typing import List\n",
    "\n",
    "class Morph:\n",
    "    def __init__(self, surface, base, pos, pos1):\n",
    "        self.surface = surface\n",
    "        self.base = base\n",
    "        self.pos = pos\n",
    "        self.pos1 = pos1\n",
    "\n",
    "    def __str__(self):\n",
    "        return 'surface[{}]\\tbase[{}]\\tpos[{}]\\tpos1[{}]'.format(self.surface, self.base, self.pos, self.pos1)\n",
    "\n",
    "class Chunk():\n",
    "    def __init__(self, morphs, dst):\n",
    "        self.morphs: List[Morph] = morphs\n",
    "        self.dst = dst\n",
    "        self.srcs = set()\n",
    "\n",
    "    def __str__(self):\n",
    "        return 'morphs[{}]\\tdst[{}]\\tsrcs[{}]'.format(self.morphs, self.dst, self.srcs)\n",
    "\n",
    "    def surface(self):\n",
    "        return ''.join([morph.surface for morph in self.morphs])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 3)"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from typing import Tuple\n",
    "\n",
    "def parse_cabocha_str(line: str) -> Tuple[str, str]:\n",
    "    \"\"\"\n",
    "    cabochaの解析結果をタプルで返す\n",
    "    \"\"\"\n",
    "    id, dst = tuple(line.split(' ')[1:3])\n",
    "    return int(id), int(dst.replace('D', ''))\n",
    "\n",
    "test_cabocha_str = '* 2 3D 0/0 0.758984'\n",
    "parse_cabocha_str(test_cabocha_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pandas import Series\n",
    "def is_cabocha_str(line: Series) -> bool:\n",
    "    \"\"\"\n",
    "    cabochaの解析結果のchunkの行かどうかを判定する\n",
    "    \"\"\"\n",
    "    return line['surface'][0] == '*' and line['pos'] is None\n",
    "\n",
    "test_cabocha_series = pd.Series(['* 2 3D 0/0 0.758984', None, None, None], index=['surface', 'pos', 'pos1', 'base'])\n",
    "is_cabocha_str(test_cabocha_series)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def is_eos(line: Series) -> bool:\n",
    "    return line['surface'] == 'EOS'\n",
    "\n",
    "test_eos_series = pd.Series(['EOS', None, None, None], index=['surface', 'pos', 'pos1', 'base'])\n",
    "is_eos(test_eos_series)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "\n",
    "def dataframe_to_sentences(df: DataFrame) -> List[List[Chunk]]:\n",
    "    sentences = []\n",
    "    sentence: List[Chunk] = []\n",
    "    chunk = None\n",
    "    for i, row in df.iterrows(): # 行をTransposeしたSeriesを返す\n",
    "        if (is_eos(row)):\n",
    "            # append\n",
    "            chunk is not None and sentence.append(chunk)\n",
    "            len(sentence) > 0 and sentences.append(sentence)\n",
    "            # reset\n",
    "            sentence = []\n",
    "            chunk = None\n",
    "        elif (is_cabocha_str(row)):\n",
    "            # append\n",
    "            chunk is not None and sentence.append(chunk)\n",
    "            # reset and set\n",
    "            id, dst = parse_cabocha_str(row['surface'])\n",
    "            morphs: List[Morph] = []\n",
    "            chunk = Chunk(morphs, dst)\n",
    "        else:\n",
    "            morph = Morph(row['surface'], row['base'], row['pos'], row['pos1'])\n",
    "            morphs.append(morph)\n",
    "            chunk.morphs = morphs\n",
    "    return sentences\n",
    "\n",
    "sentences = dataframe_to_sentences(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "def embed_src_to_sentence(sentence: List[Chunk]):\n",
    "    for i, chunk in enumerate(sentence):\n",
    "        dst_chunk = sentence[chunk.dst]\n",
    "        dst_chunk.srcs.add(i)\n",
    "\n",
    "for sentence in sentences:\n",
    "    embed_src_to_sentence(sentence)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 42. 係り元と係り先の文節の表示\n",
    "\n",
    "def extract_src_dst(sentence: List[Chunk]) -> List[str]:\n",
    "    src_dst_list = []\n",
    "    for chunk in sentence:\n",
    "        src_chunks = [sentence[src] for src in chunk.srcs]\n",
    "        src_dst_list.append(chunk.surface() + '\\t' + '\\t'.join([sc.surface() for sc in src_chunks]))\n",
    "    return src_dst_list\n",
    "\n",
    "src_dst_2d_list = [extract_src_dst(sentence) for sentence in sentences]\n",
    "src_dst_list = [item for sublist in src_dst_2d_list for item in sublist]\n",
    "\n",
    "# FIXME: 句読点の削除\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 43. 名詞を含む文節が動詞を含む文節に係るものを抽出\n",
    "\n",
    "def has_pos(chunk: Chunk, pos: str) -> bool:\n",
    "    return any([morph.pos == pos for morph in chunk.morphs])\n",
    "\n",
    "has_pos(sentences[0][0], '名詞')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_noun_depends_on_verb(sentence: List[Chunk]) -> List[str]:\n",
    "    noun_depends_on_verb_list = []\n",
    "    for chunk in sentence:\n",
    "        if has_pos(chunk, '名詞'):\n",
    "            dst_chunk = sentence[chunk.dst]\n",
    "            if has_pos(dst_chunk, '動詞'):\n",
    "                noun_depends_on_verb_list.append(chunk.surface() + '\\t' + dst_chunk.surface())\n",
    "    return noun_depends_on_verb_list\n",
    "\n",
    "noun_depends_on_verb_2d_list = [extract_noun_depends_on_verb(sentence) for sentence in sentences]\n",
    "noun_depends_on_verb_list = [item for sublist in noun_depends_on_verb_2d_list for item in sublist]\n",
    "# FIXME: 句読点の削除\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "// The Round Table\n",
      "digraph {\n",
      "\tA [label=\"King Arthur\"]\n",
      "\tB [label=\"Sir Bedevere the Wise\"]\n",
      "\tL [label=\"Sir Lancelot the Brave\"]\n",
      "\tA -> B\n",
      "\tA -> L\n",
      "\tB -> L [constraint=false]\n",
      "}\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'test-output/round-table.gv.pdf'"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from graphviz import Digraph\n",
    "dot = Digraph(comment='The Round Table')\n",
    "dot  #doctest: +ELLIPSIS\n",
    "dot.node('A', 'King Arthur')\n",
    "dot.node('B', 'Sir Bedevere the Wise')\n",
    "dot.node('L', 'Sir Lancelot the Brave')\n",
    "dot.edges(['AB', 'AL'])\n",
    "dot.edge('B', 'L', constraint='false')\n",
    "print(dot.source)  # doctest: +NORMALIZE_WHITESPACE\n",
    "dot.render('data/round-table.gv', view=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'data/係り受け木.gv.pdf'"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 44. 係り受け木の可視化\n",
    "# 始めから有向グラフで抽出してくれるライブラリはないだろうか...\n",
    "\n",
    "def sentence_to_graph(sentence: List[Chunk]) -> Digraph:\n",
    "    graph = Digraph(comment='The Round Table')\n",
    "    for i, chunk in enumerate(sentence):\n",
    "        graph.node(str(i), chunk.surface())\n",
    "        graph.edge(str(i), str(chunk.dst))\n",
    "    return graph\n",
    "\n",
    "sentence_to_graph(sentences[0]).render('data/係り受け木.gv', view=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 45. 動詞の格パターンの抽出\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "9829b077c52378d5e1bc55420cf8cc5a4f9f459501a552e8de61cb75f7311e5d"
  },
  "kernelspec": {
   "display_name": "Python 3.9.9 64-bit ('.venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
