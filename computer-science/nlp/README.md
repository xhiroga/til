# 自然言語処理 (natural language processing)

ページ構成にあたって次の情報源を参考にした。

- [自然言語処理の基礎](https://amzn.to/3VXZB2W)
- [IT Text 自然言語処理の基礎](https://amzn.to/3Lh9uEk)

## 辞書とコーパス

伝統的な自然言語処理において利用される辞書として、単語辞書の他にシソーラス (thesaurus)とコーパス (corpus)がある。
シソーラスは英語で類語辞典を意味し、treasure (宝物)同じ語源を持つ。日本語では、単なる類語辞典を越えて、単語を体系的に分類した辞典を指すことが多い。現在もアクセス可能なシソーラスに、[日本語WordNet](https://bond-lab.github.io/wnja/)がある。
コーパスは、自然言語の文章を大量に集めたもの。[言語資源開発センター](https://clrd.ninjal.ac.jp/goihyo.html)などからアクセスできる。

文章を機械的に処理する際、性能と速度はトレードオフの関係にある。英語のスペルチェックを考えると、単語単位の処理ではスペルミスしか検出できないが、動詞の前の主語を考慮すれば三単現のsのような語尾変化を検出できるようになる。そこで、文章を処理する単位を複数の連続する単語とする手法をN-gram (nグラム)と呼ぶ。

## 形態素解析

## 構文解析

## 文脈解析

## 自然言語処理の応用

文書の検索エンジンを考える。文書をキーワードの集合と見做して、検索キーワードを含む、あるいは含まないように条件にあった文書を探す考え方を、ブーリアンモデルという。それに対して、文書のキーワードに重み付けを行ったモデルをベクトル空間モデルという。文書のキーワードと検索キーワードの類似性が高い文書を探す。類似性の高さは、それぞれをベクトルと見立てた内積（ベクトルの各次元の積和）の大小を見るほかに、内積を2つのベクトルの長さで割って正規化したコサイン類似度 (cosine similarity)を用いることもある。

キーワードの重み付けの方法を考える。文書中に繰り返し「ピカチュウ」が登場したら、それはおそらくポケモンの文書だろう。つまり、ある文書に繰り返し登場するキーワードは、その文書における重みを高く設定したい。このような文書内での頻度を用いた重み付けの手法をTF(term frequency)法という。一方で、「私」「思う」といったキーワードは、文書を問わず繰り返し登場するから文書の特徴を表していない可能性が高い。そこで、その単語が文書に登場する頻度（DF (document frequency)）の逆数を対数など[^note_idf]で調整して倍率とし、これをIDF(inverse document frequency)という。TFをIDFで重み付けする方法をTF-IDF法という。
[^note_idf]: 自然言語処理の基礎（奥村学）では$idf(t)=log(N/df(t))+1$と、調整のための定数項が含まれる

例えば、次の文書に対して、「犬」のTFとIDFを計算する。

| 文書                   | 文書の全単語数                 | 「犬」のTF | 「犬」のIDF     | 「犬」のTF-IDF |
| ---------------------- | ------------------------------ | ---------- | --------------- | -------------- |
| 犬のおまわりさん       | 4 (犬,の,おまわり,さん)        | 0.25 (1/4) | 1.585 (ln(2/3)) | 0.146          |
| 猫が営むラーメン屋さん | 5 (猫,が,営む,ラーメン屋,さん) | 0 (0/5)    | 1.585 (ln(2/3)) | 0              |
| 犬と猫を飼う           | 5 (犬,と,猫,を,飼う)           | 0.2 (1/5)  | 1.585 (ln(2/3)) | 0.117          |

> [!NOTE] IDFの底は？
> 数学的には何でも構わない。通常2を使用するが、`sklearn`など実装によっては自然対数を用いることもあるという書き込みを見つけた。[^stackoverflow_56002611]出典の論文へのアクセス権がないため、それ以上の調査はできていない。
[^stackoverflow_56002611]: [When to use which base of log for tf-idf?](https://stackoverflow.com/questions/56002611/when-to-use-which-base-of-log-for-tf-idf)

## 単語ベクトル表現

## ニューラルネットワーク

[機械学習](../machine-learning/README.md)を参照。

## 未分類 (uncategorized)

- 意味ネットワーク: WIP
