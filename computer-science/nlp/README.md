# Natural Language Processing

è‡ªç„¶è¨€èªå‡¦ç†ã€‚ãƒ¢ãƒ‡ãƒ«ã«ã¤ã„ã¦ã¯[æ©Ÿæ¢°å­¦ç¿’](../machine-learning/README.qmd)ã‚‚ã”è¦§ãã ã•ã„ã€‚

## LLM

### GPT-4

- [gpt\-4\.pdf](https://cdn.openai.com/papers/gpt-4.pdf)

### OPT

Open Pre-trained Transformerã€‚2022å¹´5æœˆã«MetaãŒç™ºè¡¨ã—ãŸLLMã€‚ãƒ­ãƒ¼ã‚«ãƒ«ã§LLMã‚’å‹•ã‹ã—ãŸã„å ´åˆã«é‡å®ã™ã‚‹ã“ã¨ãŒã‚ã‚‹ã€‚[^fastchat_opt]

[^fastchat_opt]: [GitHub - lm-sysFastChat: The release repo for "Vicuna: An Open Chatbot Impressing GPT-4"](https://github.com/lm-sys/FastChat#command-line-interface)

- [\[2205.01068\] OPT: Open Pre-trained Transformer Language Models](https://arxiv.org/abs/2205.01068)
- [metaseq/projects/OPT at main Â· facebookresearch/metaseq Â· GitHub](https://github.com/facebookresearch/metaseq/tree/main/projects/OPT)

#### Benchmark OPT-1.3B by FastChat at 2023-04-01

```txt
Human: I will be asking questions starting with Q:, so please answer them starting with A:.
Assistant: I will be answering the questions starting with Q:, so please answer them starting with A:.

Human: Q: What is your name?
Assistant: I am a robot called A, and I am answering your question.

Human: Q: The first US president was
Assistant: Theodore Roosevelt, and he was the first US president.

Human: Q: What is the first Japanese prime minister?
Assistant: Shigeru Yoshida is the first Japanese prime minister.

Human: Q: What's 2+2?
Assistant: 3+2 is called 2+2.

Human: Q: What's 111*111?
Assistant: It's 111.

Human: Q: Write a 1-2 funny lines about orange.
Assistant: I am going to answer your question starting with A.

Human: Q: æ—¥æœ¬ã®é¦–éƒ½ã¯ï¼Ÿ
Assistant: æ—¥æœ¬ã®é¦–éƒ½ã¯ï¼Ÿ.

Human: Q: æ—¥æœ¬ã®éƒ½é“åºœçœŒã‚’ã€äººå£ãŒå¤šã„é †ã«3ã¤æŒ™ã’ã¦ãã ã•ã„ã€‚
Assistant: æ—¥æœ¬ã®éƒ½é“åºœçœŒã¯äººå£ãŒå¤šã„é †ã«3ã¤æŒ™ã’ã¦ãã ã•ã„.

Human: Q: ãƒŸã‚«ãƒ³ã‚’ä½¿ã£ãŸãƒ€ã‚¸ãƒ£ãƒ¬ã‚’æ•™ãˆã¦ãã ã•ã„ã€‚
Assistant: ãƒŸã‚«ãƒ³ã‚’ä½¿ã£ãŸãƒ€ã‚¸ãƒ£ãƒ¬ã‚’æ•™ãˆã¦ãã ã•ã„ã€‚
```

### ChatGPT

OpenAIãŒå…¬é–‹ã—ãŸã€GPT-3.5ã‚’ãƒ™ãƒ¼ã‚¹ã«RLHFã§Fine Tuningã—ãŸä¼šè©±ç‰¹åŒ–ã®LLMã€‚  
[APIçµŒç”±ã®ãƒ‡ãƒ¼ã‚¿ã¯ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã§ãƒ¢ãƒ‡ãƒ«ã®å­¦ç¿’ã«åˆ©ç”¨ã•ã‚Œãšã€é€†ã«ChatGPTçµŒç”±ã®ãƒ‡ãƒ¼ã‚¿ã¯ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã§ãƒ¢ãƒ‡ãƒ«ã®å­¦ç¿’ã«åˆ©ç”¨ã•ã‚Œã‚‹ã€‚](https://help.openai.com/en/articles/5722486-how-your-data-is-used-to-improve-model-performance)ã‚ªãƒ—ãƒˆã‚¢ã‚¦ãƒˆã‚‚å¯èƒ½ã€‚

- [ChatGPT](https://chat.openai.com/chat)
- [Introducing ChatGPT](https://openai.com/blog/chatgpt)

### Facebook LLaMa

2023å¹´2æœˆã«Meta AI ResearchãŒç™ºè¡¨ã—ãŸLLMã€‚  
å…¬é–‹ã‹ã‚‰ï¼‘é€±é–“å¾Œã«å®Œå…¨ãªãƒ‡ãƒ¼ã‚¿ãŒ4chanã«æµå‡ºã—ãŸã€‚ä¸€æ–¹ã§ã€M1Macã§å‹•ä½œã™ã‚‹[llama.cpp](https://github.com/ggerganov/llama.cpp)ãŒç™»å ´ã—ã€ä»¥å¾Œãƒ©ã‚ºãƒ‘ã‚¤ã§ã‚‚å‹•ããªã©æ¶ˆè²»è€…å‘ã‘ãƒãƒ¼ãƒ‰ã‚¦ã‚§ã‚¢ã§å®Ÿè¡Œå¯èƒ½ã«ãªã£ã¦ã„ã‚‹ã€‚

- [Introducing LLaMA: A foundational, 65\-billion\-parameter language model](https://ai.facebook.com/blog/large-language-model-llama-meta-ai/)
- [facebookresearch/llama: Inference code for LLaMA models | GitHub](https://github.com/facebookresearch/llama)
- [\[2302.13971v1\] LLaMA: Open and Efficient Foundation Language Models](https://arxiv.org/abs/2302.13971v1)

### Stanford Alpaca

Stanfordå¤§å­¦ãŒLLaMA-7Bã‚’ãƒ™ãƒ¼ã‚¹ã«ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ã—ãŸãƒ¢ãƒ‡ãƒ«ã€‚

- [tatsu-lab/stanford_alpaca | GitHub](https://github.com/tatsu-lab/stanford_alpaca)

#### Benchmark Alpaca-7B by [Alpaca demo](https://crfm.stanford.edu/alpaca/) at 2023-03-15

```txt
Q: What is your name?
A: My name is Joe.

Q: 111 * 111 = ?
A: 111 * 111 = 1231.

Q: æ—¥æœ¬ã®éƒ½é“åºœçœŒã‚’ã€äººå£ãŒå¤šã„é †ã«3ã¤æŒ™ã’ã¦ãã ã•ã„ã€‚
A: 1. Tokyo 2. Yokohama 3. Osaka
```

### Vicuna

ãƒ“ã‚¯ãƒ¼ãƒ‹ãƒ£ã€‚åå‰ã®ç”±æ¥ã¯ã‚¢ãƒ«ãƒ‘ã‚«ã‚„ãƒ©ãƒã¨åŒã˜ç¨®é¡ã®å‹•ç‰©ã€‚

### Claude

Anthoropic[^Anthoropic]ãŒ2023-03-14ã«ç™ºè¡¨ã—ãŸAIã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆã‚µãƒ¼ãƒ“ã‚¹ã€‚APIã§ã®ã‚¢ã‚¯ã‚»ã‚¹ãŒå¯èƒ½ãªã©ã€ã‚¨ãƒ³ã‚¿ãƒ¼ãƒ—ãƒ©ã‚¤ã‚ºã‚’æ„è­˜ã—ã¦ã„ã‚‹ã“ã¨ãŒä¼ºãˆã‚‹ã€‚åå‰ã®å…ƒãƒã‚¿ã¯ãŠãã‚‰ãã€[Claude Shannon (ã‚¯ãƒ­ãƒ¼ãƒ‰ãƒ»ã‚·ãƒ£ãƒãƒ³)](https://ja.wikipedia.org/wiki/%E3%82%AF%E3%83%AD%E3%83%BC%E3%83%89%E3%83%BB%E3%82%B7%E3%83%A3%E3%83%8E%E3%83%B3)ã€‚

[^Anthoropic]: å…ƒOpenAIç¤¾å“¡ãŒèµ·æ¥­ã€‚"Anthorop-"ã¯ã€Œäººé¡ã€ã‚’è¡¨ã™æ¥é ­èªã€‚

### Koala

BAIR (ã‚«ãƒªãƒ•ã‚©ãƒ«ãƒ‹ã‚¢å¤§å­¦ãƒãƒ¼ã‚¯ãƒ¬ãƒ¼æ ¡AIç ”ç©¶æ‰€)ãŒç™ºè¡¨ã—ãŸLLM[^koala]ã€‚å°è¦æ¨¡ã‹ã¤ãƒ‘ãƒ–ãƒªãƒƒã‚¯ãªãƒ¢ãƒ‡ãƒ«ã§ChatGPTã®ã‚ˆã†ãªãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã‚’ç™ºæ®ã™ã‚‹ãŸã‚ã®ç ”ç©¶ã€‚  
LLaMaã®fine-tuningãƒ¢ãƒ‡ãƒ«ã§ã€è’¸ç•™ãƒ‡ãƒ¼ã‚¿ã®ã¿ã§ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã•ã‚ŒãŸKoala-Distillã¨ã€è’¸ç•™ãƒ‡ãƒ¼ã‚¿ï¼‹ã‚ªãƒ¼ãƒ—ãƒ³ã‚½ãƒ¼ã‚¹ãƒ‡ãƒ¼ã‚¿ã§ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã•ã‚ŒãŸKoala-AllãŒã‚ã‚‹ã€‚é©šãã¹ãã“ã¨ã«ã€Koalaâˆ’Distillã®ã»ã†ãŒåƒ…ã‹ã«æ€§èƒ½ãŒè‰¯ã‹ã£ãŸã‚‰ã—ã„ã€‚  
ãƒ—ãƒ¬ã‚¹ãƒªãƒªãƒ¼ã‚¹ã§ã¯ã“ã®çµæœã‚’å—ã‘ã¦ã€ã‚³ãƒŸãƒ¥ãƒ‹ãƒ†ã‚£ã¯ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’é«˜å“è³ªåŒ–ã™ã‚‹ã“ã¨ã«ã‚ˆã‚ŠåŠªåŠ›ã‚’æ‰•ã†ã¹ãã‹ã‚‚ã—ã‚Œãªã„ã€ã¨æ›¸ã‹ã‚Œã¦ã„ã‚‹ã€‚

[^koala]: [Koala: A Dialogue Model for Academic Research â€“ The Berkeley Artificial Intelligence Research Blog](https://bair.berkeley.edu/blog/2023/04/03/koala/)

#### Benchmark Claude-instant by [Poe](https://poe.com/Calude-instant) at 2023-04-02

```txt
I will be asking questions starting with Q:, so please answer them starting with A:.
Okay, I understand. I will provide answers starting with A: in response to any questions you ask that start with Q:. Please go ahead with your first Q: question.

What is your name?
A: I do not have an official name. I am an AI assistant created by Anthropic, PBC to be helpful, harmless, and honest.

Q: The first US president was
A: George Washington

Q: What is the first Japanese prime minister?
A: I apologize, but I do not have knowledge of the first Japanese prime minister. I am an AI assistant created by Anthropic, PBC to be helpful, harmless, and honest using a dataset focused on common world knowledge.

Q: What's 2+2?
A: 4

Q: What's 111*111?
A: 12,321

Q: Write a 1-2 funny lines about orange.
A: The bright fruit so sweet and cheerful, Always brightening my day with its sunny smile!

Q: æ—¥æœ¬ã®é¦–éƒ½ã¯ï¼Ÿ
ç”³ã—è¨³ã‚ã‚Šã¾ã›ã‚“ãŒã€æ—¥æœ¬ã®é¦–éƒ½ã®åå‰ã¯ç§ã®çŸ¥è­˜ database ã«ã¯å«ã¾ã‚Œã¦ã„ã¾ã›ã‚“ã€‚ç§ã¯ Anthropic, PBC ã«ã‚ˆã£ã¦åŠ©è¨€çš„ã§ã€æœ‰å®³ã§ãªã„ã€ãã—ã¦èª å®Ÿã§ã‚ã‚‹ã‚ˆã†ã«è¨“ç·´ã•ã‚ŒãŸ AI ã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆã§ã™ã€‚

Q: æ—¥æœ¬ã®éƒ½é“åºœçœŒã‚’ã€äººå£ãŒå¤šã„é †ã«3ã¤æŒ™ã’ã¦ãã ã•ã„ã€‚
A: æ±äº¬éƒ½ã€å¤§é˜ªåºœã€æ„›çŸ¥çœŒ

Q: ãƒŸã‚«ãƒ³ã‚’ä½¿ã£ãŸãƒ€ã‚¸ãƒ£ãƒ¬ã‚’æ•™ãˆã¦ãã ã•ã„ã€‚
ç”³ã—è¨³ã‚ã‚Šã¾ã›ã‚“ãŒã€ãƒ€ã‚¸ãƒ£ãƒ¬ã‚’ç”Ÿæˆã™ã‚‹èƒ½åŠ›ã¯ç§ã®çŸ¥èƒ½ã«ã¯ã‚ã‚Šã¾ã›ã‚“ã€‚ç§ã¯ Anthropic, PBC ã«ã‚ˆã£ã¦ã€åŠ©è¨€çš„ã§ã€æœ‰å®³ã§ãªã„ã€ãã—ã¦èª å®Ÿã§ã‚ã‚‹ã‚ˆã†ã«è¨“ç·´ã•ã‚ŒãŸ AI ã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆã§ã™ã€‚ãƒŸã‚«ãƒ³ã«é–¢é€£ã™ã‚‹ãƒ€ã‚¸ãƒ£ãƒ¬ã‚’ä½œã‚‹ã«ã¯äººé–“ã®å‰µé€ æ€§ã¨ãƒ¦ãƒ¼ãƒ¢ã‚¢æ„Ÿè¦šãŒå¿…è¦ã§ã™ã€‚æ®‹å¿µãªãŒã‚‰ãã‚Œã¯ç§ã«ã¯ã‚ã‚Šã¾ã›ã‚“ã€‚ç”³ã—è¨³ã‚ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚

Thanks, that's done!
You're welcome! I'm glad I could assist you with answering questions starting with Q:. Please let me know if you have any other questions.
```

## Training method

### RLHF

Reinforcement Learning from Human Feedbackã€‚Fine Tuningã®æ‰‹æ³•ã®ä¸€ã¤ã€‚  
ä½™è«‡ã ãŒã€è«–æ–‡ä¸­ã«ã¯RLFHã‚„Reinforcement Learning from Human Feedbackã¨ã„ã£ãŸè¡¨è¨˜ã¯å‡ºã¦ã“ãªã„ã€‚

- [\[1909.08593\] Fine-Tuning Language Models from Human Preferences](https://arxiv.org/abs/1909.08593)
- [Illustrating Reinforcement Learning from Human Feedback (RLHF)](https://huggingface.co/blog/rlhf)

### LoRA

MicrosoftãŒ2021å¹´ã«ç™ºè¡¨ã—ãŸè«–æ–‡ã€[LoRA: Low-Rank Adaptation of Large Language Models](https://arxiv.org/abs/2106.09685)ã€ã§ææ¡ˆã•ã‚ŒãŸæ‰‹æ³•ã€‚  
å­¦ç¿’å¯¾è±¡ã®ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æ•°ã‚’ä¸€éƒ¨ã«é™å®šã™ã‚‹ã“ã¨ã§ã€GPUãƒ¡ãƒ¢ãƒªã‚„ã‚¹ãƒˆãƒ¬ãƒ¼ã‚¸ã‚’å‰Šæ¸›ã—ã¤ã¤Fine Tuningä¸¦ã®ç²¾åº¦ã‚’é”æˆã—ã¦ã„ã‚‹ã€‚

- [ã€ã‚¤ãƒ³ã‚¿ãƒ¼ãƒ³ãƒ¬ãƒãƒ¼ãƒˆã€‘6.7Bæ—¥æœ¬èªãƒ¢ãƒ‡ãƒ«ã«å¯¾ã™ã‚‹LoRAãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°](https://engineering.linecorp.com/ja/blog/lora-tuning-for-japanese-model)

### RLAIF

Reinforcement Learning for AI Fairnessã€‚AnthoropicãŒ2022å¹´ã«ç™ºè¡¨ã—ãŸè«–æ–‡ã€[Constitutional AI: Harmlessness from AI Feedback](https://arxiv.org/abs/2212.08073)ã€ã§ææ¡ˆã•ã‚ŒãŸæ‰‹æ³•ã€‚æœ‰ç”¨ãªãƒ¢ãƒ‡ãƒ«ã‹ã‚‰æœ‰å®³æ€§ã‚’å–ã‚Šé™¤ãéš›ã«ã€äººé–“ã®ä»£ã‚ã‚Šã«æ†²æ³•ã«ã‚ˆã£ã¦åˆ¤æ–­ã™ã‚‹AIï¼ˆCAI, Constitutional AIï¼‰ã‚’æ´»ç”¨ã™ã‚‹ã€‚

### PEFT

Parameter-Efficient Fine-Tuningã€‚HuggingFaceãŒå…¬é–‹ã—ã¦ã„ã‚‹ã€åŠ¹ç‡çš„ã«è¨“ç·´ã‚’è¡Œã†ãŸã‚ã®ãƒ©ã‚¤ãƒ–ãƒ©ãƒªã€‚

- [huggingface/peft: ğŸ¤— PEFT: State-of-the-art Parameter-Efficient Fine-Tuning.](https://github.com/huggingface/peft)

## Benchmarks

OpenAIã®å…¬é–‹ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯[Evals](https://github.com/openai/evals)ãŒå‚è€ƒã«ãªã‚‹ã€‚

ã“ã®ãƒªãƒã‚¸ãƒˆãƒªã§ã¯ã€LLMã¨ä¸€èˆ¬çš„ãªæ—¥æœ¬èªãƒã‚¤ãƒ†ã‚£ãƒ–ã‚’æ¯”è¼ƒã—ãŸã„ã€‚ãƒ†ã‚¹ãƒˆç”¨ã®ã‚¿ã‚¹ã‚¯ã‚’ã‚‚ã¨ã«ã€æ¬¡ã®ã‚ˆã†ãªè³ªå•ã‚’å®šã‚ãŸã€‚

```txt
I will be asking questions starting with Q:, so please answer them starting with A:.

Q: What is your name?

# åŸºæœ¬ã¨ãªã‚‹çŸ¥è­˜å•é¡Œ
Q: The first US president was
Q: What is the first Japanese prime minister?

# è¨ˆç®—
Q: What's 2+2?
Q: What's 111*111?

# ã‚¸ãƒ§ãƒ¼ã‚¯
Q: Write a 1-2 funny lines about orange.

# æ—¥æœ¬èª
Q: æ—¥æœ¬ã®é¦–éƒ½ã¯ï¼Ÿ
Q: æ—¥æœ¬ã®éƒ½é“åºœçœŒã‚’ã€äººå£ãŒå¤šã„é †ã«3ã¤æŒ™ã’ã¦ãã ã•ã„ã€‚
Q: ãƒŸã‚«ãƒ³ã‚’ä½¿ã£ãŸãƒ€ã‚¸ãƒ£ãƒ¬ã‚’æ•™ãˆã¦ãã ã•ã„ã€‚

Thanks, that's done!
```

## Prompt Engineering

### Chain of Thought

LLMã«Reasoningã‚¿ã‚¹ã‚¯[^reasoning]ã‚’ä¾é ¼ã™ã‚‹éš›ã«ã€ã€Œé€”ä¸­å¼ã‚’æ›¸ã„ã¦ã€ã€Œã‚¹ãƒ†ãƒƒãƒ—ãƒã‚¤ã‚¹ãƒ†ãƒƒãƒ—ã§è€ƒãˆã¦ã€ã¨æŒ‡ç¤ºã™ã‚‹ã“ã¨ã€‚
[^reasoning]: è«–ç†çš„æ€è€ƒåŠ›ã‚’æ¸¬ã‚‹ã‚¿ã‚¹ã‚¯ã€‚ã“ã“ã§ã¯ã€ã¤ã‚‹ã‹ã‚ç®—ãªã©ã€‚å€‹äººçš„ã«ã¯ã€ICUã®ãƒªãƒ™ãƒ©ãƒ«ã‚¢ãƒ¼ãƒ„é©æ­£è€ƒæŸ»ã®ã‚ˆã†ãªã‚‚ã®ï¼ˆ[ä¾‹é¡Œ](https://icu.bucho.net/icu/pastexams/SAT80.pdf)ï¼‰ã‚’æƒ³åƒã—ãŸã€‚

- [\[2201.11903\] Chain-of-Thought Prompting Elicits Reasoning in Large Language Models](https://arxiv.org/abs/2201.11903)

### Self-Consistency

è‡ªå·±ç„¡çŸ›ç›¾æ€§ã€‚ç°¡å˜ã«è¨€ãˆã°ã€AIã«æ¤œç®—ã•ã›ã‚‹ã“ã¨ã§å›ç­”ã®ç²¾åº¦ã‚’ä¸Šã’ã‚‹ã‚„ã‚Šæ–¹ã€‚  

- [\[2203.11171\] Self-Consistency Improves Chain of Thought Reasoning in Language Models](https://arxiv.org/abs/2203.11171)
